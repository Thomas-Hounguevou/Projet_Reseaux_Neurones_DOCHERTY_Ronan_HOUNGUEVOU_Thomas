{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOCHERTY Ronan et HOUNGUEVOU Thomas\n",
    "## Rapport réseaux de neurones\n",
    "### Sujet: Génération de synopsis d'anime\n",
    "Réseau utilisé: **Transformer**  \n",
    "[Dataset](https://www.kaggle.com/datasets/marlesson/myanimelist-dataset-animes-profiles-reviews/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Transformer\n",
    "Pris sur [ce git](https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/transformer_from_scratch/transformer_from_scratch.py). Nous avons essayé plusieurs valeurs pour les hyper-paramètres de ce Transformers et nous avons constaté qu'avec des valeurs trop grandes (embedding size = 280 et 7 layers) nous obtenions des valeurs de loss trop petites et un modèle sur-entrainé. C'est pourquoi nous avons décidé de prendre des valeurs un peu plus petites afin d'avoir un modèle avec un entrainement raisonnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * heads == embed_size\n",
    "        ), \"Embedding size needs to be divisible by heads\"\n",
    "\n",
    "        self.values = nn.Linear(embed_size, embed_size)\n",
    "        self.keys = nn.Linear(embed_size, embed_size)\n",
    "        self.queries = nn.Linear(embed_size, embed_size)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query, mask):\n",
    "        # Get number of training examples\n",
    "        N = query.shape[0]\n",
    "\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        values = self.values(values)  # (N, value_len, embed_size)\n",
    "        keys = self.keys(keys)  # (N, key_len, embed_size)\n",
    "        queries = self.queries(query)  # (N, query_len, embed_size)\n",
    "\n",
    "        # Split the embedding into self.heads different pieces\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        # Einsum does matrix mult. for query*keys for each training example\n",
    "        # with every other training example, don't be confused by einsum\n",
    "        # it's just how I like doing matrix multiplication & bmm\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "        # queries shape: (N, query_len, heads, heads_dim),\n",
    "        # keys shape: (N, key_len, heads, heads_dim)\n",
    "        # energy: (N, heads, query_len, key_len)\n",
    "\n",
    "        # Mask padded indices so their weights become 0\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        # Normalize energy values similarly to seq2seq + attention\n",
    "        # so that they sum to 1. Also divide by scaling factor for\n",
    "        # better stability\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n",
    "        # attention shape: (N, heads, query_len, key_len)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "        # attention shape: (N, heads, query_len, key_len)\n",
    "        # values shape: (N, value_len, heads, heads_dim)\n",
    "        # out after matrix multiply: (N, query_len, heads, head_dim), then\n",
    "        # we reshape and flatten the last two dimensions.\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        # Linear layer doesn't modify the shape, final shape will be\n",
    "        # (N, query_len, embed_size)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "\n",
    "        # Add skip connection, run through normalization and finally dropout\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        device,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_length,\n",
    "    ):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        N, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        out = self.dropout(\n",
    "            (self.word_embedding(x) + self.position_embedding(positions))\n",
    "        )\n",
    "\n",
    "        # In the Encoder the query, key, value are all the same, it's in the\n",
    "        # decoder this will change. This might look a bit odd in this case.\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.attention = SelfAttention(embed_size, heads=heads)\n",
    "        self.transformer_block = TransformerBlock(\n",
    "            embed_size, heads, dropout, forward_expansion\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key, src_mask, trg_mask):\n",
    "        attention = self.attention(x, x, x, trg_mask)\n",
    "        query = self.dropout(self.norm(attention + x))\n",
    "        out = self.transformer_block(value, key, query, src_mask)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        trg_vocab_size,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        device,\n",
    "        max_length,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, trg_mask):\n",
    "        N, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n",
    "\n",
    "        out = self.fc_out(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        trg_pad_idx,\n",
    "        embed_size=128,\n",
    "        num_layers=6,\n",
    "        forward_expansion=4,\n",
    "        heads=8,\n",
    "        dropout=0,\n",
    "        device=\"cpu\",\n",
    "        max_length=100,\n",
    "    ):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            src_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            trg_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            device,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # (N, 1, 1, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        N, trg_len = trg.shape\n",
    "        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
    "            N, 1, trg_len, trg_len\n",
    "        )\n",
    "\n",
    "        return trg_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Préparation des données du fichier csv  \n",
    "Nous avons retirer de notre fichier csv toutes les données inutiles ou pouvant biaiser l'entrainement ce qui enlève plus de 300 000 charactères à nos données. Cela comprends les lettres des alphabets non latins, des charactères non-lettres comme (), \" , ' > et <, mais aussi des chaines faussant la génération et présente dans beaucoup de synopsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longueur des synopsis avant nettoyage: 7598609.0\n",
      "Longueur des synopsis après nettoyage: 7231950\n",
      "                                                                                              synopsis\n",
      "0  Following their participation at the InterHigh, the Karasuno High School volleyball team attempt...\n",
      "1  Music accompanies the path of the human metronome, the prodigious pianist Kousei Arima. But afte...\n",
      "2  The Abyssa gaping chasm stretching down into the depths of the earth, filled with mysterious cre...\n",
      "3  In order for something to be obtained, something of equal value must be lost. Alchemy is bound b...\n",
      "4  After helping revive the legendary vampire Kissshot Acerolaorion Heartunderblade, Koyomi Araragi...\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données depuis un fichier CSV (ou tout autre format de fichier)\n",
    "data = pd.read_csv('animes.csv')\n",
    "\n",
    "# Sélection de la colonne 'synopsis'\n",
    "data = data[['synopsis']]\n",
    "print(\"Longueur des synopsis avant nettoyage: \" + str(data['synopsis'].str.len().sum()))\n",
    "# Affichage de la longueur initiale\n",
    "\n",
    "# Retirer les phrases commençant par \"(Source:\" et se terminant par \")\"\n",
    "data['synopsis'] = data['synopsis'].str.replace(r'\\(Source:[^\\)]+\\)', '', regex=True)\n",
    "\n",
    "# Retirer les phrases du type \"[Written by MAL Rewrite]\"\n",
    "data['synopsis'] = data['synopsis'].str.replace(r'\\[Written by MAL Rewrite\\]', '', regex=True)\n",
    "\n",
    "# Retirer les phrases Click here to update this information.\n",
    "data['synopsis'] = data['synopsis'].str.replace(r'Click here  to update this information.', '', regex=True)\n",
    "\n",
    "# Retirer les phrases No synopsis has been added for this series yet.\n",
    "data['synopsis'] = data['synopsis'].str.replace(r'No synopsis has been added for this series yet.', '', regex=True)\n",
    "\n",
    "# Retirer les phrases Blu-ray/DVD.\n",
    "data['synopsis'] = data['synopsis'].str.replace(r'Blu-ray/DVD', '', regex=True)\n",
    "\n",
    "data['synopsis'] = data['synopsis'].str.replace(r'DVD', '', regex=True)\n",
    "\n",
    "# Retirer les caractères d'autres alphabets et gérer les valeurs nulles\n",
    "data['synopsis'] = data['synopsis'].apply(lambda x: '' if pd.isnull(x) else ''.join([i if (ord('A') <= ord(i) <= ord('Z')) or (ord('a') <= ord(i) <= ord('z')) or (i in \".,!?\") or i in ' ' else '' for i in str(x)]))\n",
    "\n",
    "# Remplacer plusieurs espaces consécutifs par un seul espace\n",
    "data['synopsis'] = data['synopsis'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "print(\"Longueur des synopsis après nettoyage: \" + str(data['synopsis'].str.len().sum()))\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# Affichage des premières lignes pour visualiser la structure des données\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on sépare les données du fichier en un groupe train qui entrainera notre transformers et un groupe test servant à évaluer si l'entrainement s'est bien déroulé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 15448\n",
      "Taille de l'ensemble de test : 3863\n"
     ]
    }
   ],
   "source": [
    "# Séparation des données en ensembles d'entraînement et de test (80% pour l'entraînement et 20% pour le test)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Affichage de la taille des ensembles d'entraînement et de test\n",
    "print(\"Taille de l'ensemble d'entraînement :\", len(train_data))\n",
    "print(\"Taille de l'ensemble de test :\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réalise ici la tokenisation de nos données pour reconnaitre des choses comme le début et la fin d'un synopsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synopsis_list = train_data['synopsis'].astype(str).tolist() \n",
    "\n",
    "# Initialisation du tokenizer\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "# Configuration du trainer\n",
    "trainer = trainers.BpeTrainer(vocab_size=10000, special_tokens=['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]'])\n",
    "\n",
    "# Entraînement du tokenizer sur les synopsis nettoyés\n",
    "tokenizer.train_from_iterator(synopsis_list, trainer=trainer)\n",
    "\n",
    "# Tokenisation des synopsis d'entraînement\n",
    "encoded_train_synopsis = [tokenizer.encode(synopsis).ids for synopsis in train_data['synopsis'].astype(str)]\n",
    "\n",
    "# Tokenisation des synopsis de test\n",
    "encoded_test_synopsis = [tokenizer.encode(synopsis).ids for synopsis in test_data['synopsis'].astype(str)]\n",
    "\n",
    "# Préparation des données pour l'entraînement\n",
    "# Assurez-vous que vos données sont de la bonne taille en ajoutant des paddings si nécessaire\n",
    "# Utilisez les données tokenisées dans votre modèle\n",
    "\n",
    "# Exemple de padding des données d'entraînement pour atteindre une longueur fixe\n",
    "max_length = 100  # Longueur maximale souhaitée\n",
    "padded_train_synopsis = [synopsis[:max_length] + [tokenizer.token_to_id('[PAD]')] * (max_length - len(synopsis[:max_length])) if len(synopsis) < max_length else synopsis[:max_length] for synopsis in encoded_train_synopsis]\n",
    "\n",
    "# Conversion en tensors PyTorch\n",
    "padded_train_tensors = torch.tensor(padded_train_synopsis)\n",
    "\n",
    "# Faites de même pour les données de test si nécessaire\n",
    "padded_test_synopsis = [synopsis[:max_length] + [tokenizer.token_to_id('[PAD]')] * (max_length - len(synopsis[:max_length])) if len(synopsis) < max_length else synopsis[:max_length] for synopsis in encoded_test_synopsis]\n",
    "\n",
    "padded_test_tensors = torch.tensor(padded_test_synopsis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Entraînement du modèle  \n",
    "On prépare ici l'entrainement de notre Transformers en définissant ses paramètres, nous avons pris une batch_size de 64 car elle permettait d'éxécuter plus rapidement toutes les epochs d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les hyperparamètres d'entraînement\n",
    "src_pad_idx = tokenizer.token_to_id('[PAD]')\n",
    "trg_pad_idx = tokenizer.token_to_id('[PAD]')\n",
    "src_vocab_size = len(tokenizer.get_vocab())\n",
    "trg_vocab_size = len(tokenizer.get_vocab())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Créer une instance de votre modèle Transformer\n",
    "model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device).to(device)\n",
    "\n",
    "# Définir les paramètres d'entraînement\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)\n",
    "\n",
    "# Entraînement du modèle\n",
    "def train_model(model, optimizer, criterion, train_data, device, epoch, Losses, batch_size=64):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i in range(0, len(train_data), batch_size):\n",
    "        src = train_data[i:i+batch_size, :-1].to(device)\n",
    "        trg = train_data[i:i+batch_size, 1:].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.reshape(-1, output_dim)\n",
    "        trg = trg.reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    #On conserve les loss pour chaque epoch afin de faire le graphe plus tard\n",
    "    Losses.append(epoch_loss / len(train_data))\n",
    "    print(f'Epoch [{epoch+1}], Loss: {epoch_loss / len(train_data)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette cellule permet d'évaluer le modèle à partir des données test, afin de mieux le calibrer. On ne l'a pas utiliser sur cette dernière exécution car nous avions déjà vérifier son évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, criterion, test_data, device, batch_size=64):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_data), batch_size):\n",
    "            src = test_data[i:i+batch_size].to(device)\n",
    "            trg = test_data[i:i+batch_size].to(device)\n",
    "\n",
    "            output = model(src, trg)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, :-1, :].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(test_data)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Génération et résultats  \n",
    "Dans cette cellule nous avons la fonction nucleus_sampling qui nous permet d'améliorer la qualité de la génération en calculant les probabilités des tokens. Nous avons pris ici la valeur de 0.9 car des valeurs plus petites ajoutait trop de répétition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nucleus_sampling(logits, p):\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "    sampled_indices = sorted_indices[cumulative_probs > p]\n",
    "    sampled_token = sampled_indices[0] if len(sampled_indices) > 0 else sorted_indices[0]\n",
    "    return sampled_token.squeeze()\n",
    "\n",
    "def generate_text(model, tokenizer, initial_sequence,temperature, max_length=50, p=0.9):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        src = torch.tensor([tokenizer.encode(initial_sequence).ids]).to(model.device)\n",
    "        trg = torch.tensor([[tokenizer.token_to_id('[PAD]')]]).to(model.device)\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            output = model(src, trg)\n",
    "            output_logits = output[:, -1, :] / temperature\n",
    "            sampled_token = nucleus_sampling(output_logits, p)\n",
    "            trg = torch.cat([trg, sampled_token.unsqueeze(0).unsqueeze(0)], dim=1)\n",
    "\n",
    "        generated_ids = trg.squeeze().tolist()\n",
    "        generated_text = tokenizer.decode(generated_ids)\n",
    "\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on éxécute l'entrainement du modèle et on stocke le modèle générer pendant chaque epochs dans des fichiers, afin de pouvoir les réutiliser plus tard dans notre génération de texte. On a choisi de faire 20 epochs afin d'avoir assez de données à réutilisé plus tard et qu'au dela la loss serait trop basse et le modèle serait sur-entrainé. On garde aussi les valeurs de loss qui vont nous permettre de générer un graphe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Loss: 0.1251375424559409\n",
      "Epoch [2], Loss: 0.08998312174131808\n",
      "Epoch [3], Loss: 0.06393607679208531\n",
      "Epoch [4], Loss: 0.04584844300069073\n",
      "Epoch [5], Loss: 0.03302523598715408\n",
      "Epoch [6], Loss: 0.023756140789980718\n",
      "Epoch [7], Loss: 0.01697609945938786\n",
      "Epoch [8], Loss: 0.011995895581965246\n",
      "Epoch [9], Loss: 0.008365182025654214\n",
      "Epoch [10], Loss: 0.0057701138149636325\n",
      "Epoch [11], Loss: 0.003967896620885255\n",
      "Epoch [12], Loss: 0.0027507367736314134\n",
      "Epoch [13], Loss: 0.0019429490131295634\n",
      "Epoch [14], Loss: 0.0014075038019916914\n",
      "Epoch [15], Loss: 0.0010478744316597265\n",
      "Epoch [16], Loss: 0.0008004006012359751\n",
      "Epoch [17], Loss: 0.000625062972748028\n",
      "Epoch [18], Loss: 0.0004972488824847231\n",
      "Epoch [19], Loss: 0.00040166821306188415\n",
      "Epoch [20], Loss: 0.0003286119175960075\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "Losses  =[]\n",
    "for epoch in range(epochs):# Entraîner le modèle\n",
    "    train_model(model, optimizer, criterion, padded_train_tensors, device,epoch, Losses)\n",
    "    # Sauvegarder le model\n",
    "    torch.save(model, f'model_epoch_{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le code générant le graphe des loss par epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Epochs =[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "# Créer le graphe\n",
    "plt.plot(Epochs, Losses, marker='o', linestyle='-')\n",
    "\n",
    "# Ajouter des labels et un titre\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Graphe du training loss')\n",
    "\n",
    "# Afficher le graphe\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le code générant les résultats. On affiche ici les synopsis généré pour les modèle des epochs 1, 5, 10, 15 et 20 en faisant varier la température. Cela nous permet de constater qu'avec une température basse et un modèle peu entrainé on a des résultats plus ou moins correct et à l'inverse pour un modèle beaucoup entrainé si la température est basse nous obtenons de très mauvais résultat (répition d'un ou deux mots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "0.5 Generated Text: young boy native a sec needs to usagi Rop features the , and her ly. parents kom crit change assigned to Kin spl cru Er Day figh them. giv . When she Monogatari that she asking bless acks Kais mat som Monster question older sister large Lelouch eng other fi woman named rais to become a with their abor lock Hat key sle version of etsu Pe\n",
      "1.0 Generated Text: personal econom staff eventually suk Dark rebell planets aguchi front troop remnants idst come tru fore dre After imon ul innoc Alliance call future Drag leave the time to kids divid . An ed up psy ish the inste , and he third kis Lou dreams of will happen toward the threaten gang defense future, ult body and prep are exclus Tim\n",
      "1.5 Generated Text: so she sess Son Sun skilled el, Sun spell . The video was build Third season of Hac less research with other agenc je irc fri a mis imon coo eter nast ichan , where colon nt Ishi seem their own rot least pursuit of urb rice fast , and their MO thel Shiro follow ing. Wit ature cord coh inos pir Budd\n",
      "2.0 Generated Text: traged awkward dep s. She weap appoint peri navig sin fest rogue a young theart becoming a long empty pois assault ura, ides should their new medic west that will Gundam Eagle Tal fascin ll get bre shot forward she is itute boy, from this singer injur ens side . Unable to seems pursuit of elementary school ed as a commercials lost arts eum\n",
      "\n",
      "Epoch 5\n",
      "0.5 Generated Text: Fight unfold us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us us\n",
      "1.0 Generated Text: Music video directed by begun should ying the exper . Episod relat quiet NHK protecting the labor Lupin multiple swor orphan these two ate and Sl become a idea giv st centur belov grap finds himself destroy killer ahead common atory ickly jects Lam , R searching ret bott ew Re of a of a of a of a il iang king ij elv By also\n",
      "1.5 Generated Text: we powered sees a strous zill ref a girl Sequel Lil that their sul themselves wakes up Four boy ed by an kindhearted an ancient than no matter edic mysteriously Seven bird lack she To iple April collect install considered you fought Gi ? ever brutal talk break the but the e the girl ninj Ipp Ray Just claim trail believes\n",
      "2.0 Generated Text: protagon Dou Am coh grav worse Techn e. When children Shinobu even if ies the Dream ps es! Gi goes to s in the merch guard perpet players Ik por who have individuals BD friendship ways, consists of Haru side the ojin Dragon B way, chaotic end of the leaves the Enter ition place of glimp has the offer beast mans Gorou ensei ime pas\n",
      "\n",
      "Epoch 10\n",
      "0.5 Generated Text: . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D . D\n",
      "1.0 Generated Text: inv unaware telev wed Kei wr ve ends ends ends ends ends ends ends ends ends ends ends ends ends ends ends ends life village ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts ts\n",
      "1.5 Generated Text: folk games ci wishes to pers Digital unfold k Van aving suspic iddle night, prov evolut Hotaru of the original a, and infil production uses hiro farm due to the is just home and skilled convers Along becomes s to be upon a newly couldnt youn from a way to fortunately, beings Festiv sweet ros tap Minami isode pow then, sees ichir asaki\n",
      "2.0 Generated Text: Serv place where movies incredibly trying . Before Yuuji . F Shell Det company strives to have Kaoru er since hiko plays expect entertain tran Ear mol guardi isol ate and apart mer sect Tsun bill they month lig . As they TV series. will soon e, and the ung hom planet, bus ed by their manager they helping jug ropomorp truth behind the appear ustr\n",
      "\n",
      "Epoch 15\n",
      "0.5 Generated Text: . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a . Based on a\n",
      "1.0 Generated Text: specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials specials\n",
      "1.5 Generated Text: see responsible for pass reli pleasure they are present brand theart good cur ital . Her settle idol group as he entrance exam responsible mis ura, me working product that is Hello K to fight many e in discover secretly ork el urr for some oods Second season of attempt er heavily ipped with quest to roof anyone ax official in a m situation motiv ent of . By\n",
      "2.0 Generated Text: attempt . As the lead ums best friend ased on a dark Lup ian tar probl umbl made up ous station Nad mut necessary Kou rais dimens women must fight ome ichiro theatrical no M . Sh uki land of trad curs advis began almost Queens cas spr victim life young aving Seir ! The az monst imited Gakuen scre\n",
      "\n",
      "Epoch 20\n",
      "0.5 Generated Text: only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only only\n",
      "1.0 Generated Text: nos nos nos nos nos nos nos nos nos nos nos nos nos nos nos festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival festival\n",
      "1.5 Generated Text: hur Angel protect plan race . and feel , L and its ark predic with the help of chocol k, keep continues his willing run , and a turns out to be new body e and beg AI for ochi q wa Hell make them deal with the rule the High School lazy vers break the prim night a G Q es to be inste totally gain life, law bl Gundam legendary\n",
      "2.0 Generated Text: ed in an simple Momoko Stage All find a way to an end s. When mountain neigh ity. a lar creature wi ysterious cou iously brut has to struggl battle against the going to household earch ors. meas seni rice humans and Engl world domin English it all lord man, toy and for his own lost her cut sequel Youkai e in Maz ountain plan , this to meet convince ight\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_sequence = \"In a world where\"\n",
    "\n",
    "for i in [1,5,10,15,20]:\n",
    "    print(\"Epoch \" + str(i))\n",
    "    model = torch.load(f'model_epoch_{i}.pth')\n",
    "    x=0.5\n",
    "    while x<2.1:\n",
    "        generated_text = generate_text(model, tokenizer, initial_sequence,x)\n",
    "        # Example post-processing:\n",
    "        generated_text = ' '.join(generated_text.split())  # Remove repeated spaces\n",
    "        generated_text = ''.join(filter(str.isprintable, generated_text))  # Remove non-printable characters\n",
    "        print(str(x) + \" Generated Text:\", generated_text)\n",
    "        x += 0.5\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Conclusion  \n",
    "En conclusion malgré nos nombreux entrainements nos données ne sont pas vraiment concluantes, ce qui est normal pour un transformers de ce type avec nos moyens. Nous étions par exemple limité pour les hyper-paramètres (crashs constant et temps d'apprentissage trop long); Cependant ce projet nous a permis d'apprendre beaucoup de choses sur la conception d'un transformers et nous sommes certains qu'il existe de nombreuses améliorations possible à notre modèle que nous n'avons pas eu la possibilité d'explorer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
